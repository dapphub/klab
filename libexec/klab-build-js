#!/usr/bin/env node

const fs            = require("fs");
const path          = require("path");
const marked        = require("marked");
const {docopt}      = require("docopt");
const clc           = require("cli-color");
const _             = require("lodash");
const kjson         = require("../lib/kjson.js");
const kast          = require("../lib/kast.js");
const { execSync }  = require('child_process');
const makeConfig    = require("../lib/config.js");
const {
  proofCollection,
  makePrelude,
  makeRules,
  getActs,
  parseAct,
  buildAct,
  buildActs,
  caseSplitAct,
  newCleanup,
  makeInterabiExhaustiveness
}                   = require("../lib/build.js");
const {
  ensureDirs,
  getKlabHEAD,
  read,
  revert,
  sha3,
  testPath,
  warn,
}                   = require("../lib/util.js");
const __a2n = act => act.subject + "_" + act.name;

const KLAB_OUT = process.env.KLAB_OUT || "out";

const usage = `
Usage:
  klab build [options] [<spec>]

Options:
  --filter=<filter>
  --debug
`
const cmd = docopt(usage, {
  argv: ["build"].concat(process.argv.slice(2))
});

if (!testPath("./config.json")) {revert("No config.json file in directory. Review `klab/examples` folder for inspiration")}
const config_json   = JSON.parse(fs.readFileSync("./config.json"));
const config        = makeConfig(config_json);
const config_path   = cmd["<spec>"] || config.src.specification;
const filter_subject= cmd["--filter"] || null;
const OOGActs       = config.oog || [];
const splitActs     = config.split_fail  || [];
const timeouts      = config.timeouts || {}
const memory        = config.memory || {}
const DEBUG         = cmd["--debug"] || false;
config.DEBUG        = DEBUG;
const raw_md_config = Array.isArray(config_path) && config_path.map(p => read(p)).join("\n\n") || read(config_path)

// RULES
var {rules_str} = makeRules(config);
// prelude
const {prelude_str, write_prelude} = makePrelude(config);
// TODO error when not set
const KLAB_EVMS_PATH = process.env.KLAB_EVMS_PATH || path.join(__dirname, '..', 'evm-semantics');
if ('evm-semantics' !== KLAB_EVMS_PATH.match(/([^\/]*)\/*$/)[1]) {
  throw new Error(`Wrong EVMS path: ${KLAB_EVMS_PATH}`);
}
const EVM_SEMANTICS_VERSION = execSync(`git rev-parse HEAD`, {
  cwd: KLAB_EVMS_PATH,
  encoding: 'utf8'
});

const bin_defs = Object.keys(config.implementations)
  .map(alias => {
    const name = config.implementations[alias].name;
    const c = config.contracts[name];
    const bin = c.bin;
    const bin_runtime = c.bin_runtime;
    const binDef  = `syntax WordStack ::= "${alias}_bin"`;
    const binRule = `rule ${alias}_bin => #parseByteStack("0x${bin}") [macro]\n`;
    const runtimeDef  = `syntax WordStack ::= "${alias}_bin_runtime"`;
    const runtimeRule = `rule ${alias}_bin_runtime => #parseByteStack("0x${bin_runtime}") [macro]`;
    return [binDef, binRule, runtimeDef, runtimeRule].join("\n")
  }).join('\n\n')

config.get_proof_hash = ({name, spec}) => {
  let proof = {
    bin_defs,
    evms: EVM_SEMANTICS_VERSION,
    klab: getKlabHEAD(),
    rules: rules_str,
    smt_prelude: prelude_str,
    spec : spec,
    timeout: timeouts[name] || null,
    smt_prelude: prelude_str,
  }
  if (memory[name]) proof.memory = memory[name];
  return sha3(JSON.stringify(proof))
}

const exhaustiveness_obligations = [];
const exhaustiveness = {};

Object.keys(config.implementations)
  .forEach(alias => {
    const cname = config.implementations[alias].name
    const name = alias + "__exhaustiveness";
    const {id, module, status} = makeInterabiExhaustiveness(alias, cname, config.contracts[cname])

    // TODO - write meta/data and name

    fs.writeFileSync(path.join(KLAB_OUT, "meta", "name", name), id);
    // hash -> data
    fs.writeFileSync(path.join(KLAB_OUT, "meta", "data", id), JSON.stringify({
      name,
      src: config.src,
      srcs: config.srcs,
      contracts: config.contracts,
      implementations: config.implementations
    }));

    fs.writeFileSync(path.join(KLAB_OUT, "specs", `${id}.k`), module)

    if(status == "????") {
      console.log(id, name);
      exhaustiveness_obligations.push(name)
    }
    exhaustiveness[cname] = {
      hash: id,
      name,
      spec: module,
      status
    }
  })


// 1. get acts
//    return a [behaviour]
// 2. parse acts
//    parses every behaviour into a structured object
// 3. build acts

// const acts_str_arr = getActs(raw_md_config);

const tokens        = marked.lexer(raw_md_config)
const parsed_tokens = tokens
  .map(t => {
    if(t.type == 'code' && t.lang === "act") {
      const parsedAct = parseAct(config)(t.text, true);
      const cases = caseSplitAct(config)(parsedAct);
      return {
        type: 'code',
        lang: "act",
        obj: parsedAct,
        cases: cases,
        text: newCleanup(parsedAct, t.text)
      };
    } else {
      return t;
    }
  });


const act_collection = parsed_tokens
  .filter(e => e.type === "code" && e.lang == "act")
  .map(e => e.cases)
  .reduce((a, cs) => a.concat(cs), [])

// for each case - buildAct
const act_proofs = proofCollection(config)(act_collection)

// recursively enrich cases based on dependencies and completion
const build_proofs = buildActs(config, act_proofs);

const final_tokens = parsed_tokens
  .map(t => {
    if(t.type == "code" && t.lang == "act") {
      const cases = Object.keys(act_proofs)
        .map(name => act_proofs[name])
        .filter(c => __a2n(c.act) == __a2n(t.obj))
        // .forEach(c => {
        //   console.log(c.act.name);
        //   console.log(__a);
        // })

      return {...t, cases};
    } else {
      return t;
    }
  })

// TODO - enriched cases should be exported here.
fs.writeFileSync(path.join(KLAB_OUT, "exhaustiveness.tmp.json"), JSON.stringify(exhaustiveness));
fs.writeFileSync(path.join(KLAB_OUT, "report.tmp.json"), JSON.stringify(final_tokens));
fs.writeFileSync(path.join(KLAB_OUT, "config.tmp.json"), JSON.stringify(config));


// write module
Object.keys(build_proofs)
.filter(proof_name => act_proofs[proof_name].hash)
.forEach(proof_name => {
  const rule = act_proofs[proof_name];
  // let _rules      = [rule.spec].concat(rule.ctx.spec)
  // let module      = kjson.renderModule(_rules, rule.name)
  const module_path = path.join(KLAB_OUT, "specs", `${rule.hash}.k`)

  var old_module  = "";
  if(testPath(module_path)) old_module = read(module_path);
  if(old_module != rule.module) {
    console.log(rule.hash + " " + rule.name + rule.ctx.map(r => "\n - " + r.name));
    fs.writeFileSync(module_path, rule.module);
  }
  // if(rule.gas_module) {
  //   const gas_module_path = path.join(KLAB_OUT, "gas", `${rule.hash}gas.k`)
  //   fs.writeFileSync(gas_module_path, rule.gas_module);
  // }

  // METADATA
  // name -> hash
  fs.writeFileSync(path.join(KLAB_OUT, "meta", "name", rule.name), rule.hash);
  // hash -> data
  fs.writeFileSync(path.join(KLAB_OUT, "meta", "data", rule.hash), JSON.stringify({
    v2n: rule.v2n,
    act: rule.act_name,
    name: rule.name,
    src: config.src,
    srcs: config.srcs,
    contracts: config.contracts,
    implementations: config.implementations
  }));
})

var obligations = Object.keys(act_proofs)
  .filter(n => act_proofs[n].status === '????')
  .filter(n => !(n in timeouts))
  .concat(exhaustiveness_obligations)
  .sort((a, b) => Math.random() - 0.5)

if(obligations.length == 0) {
  obligations = Object.keys(act_proofs)
  .filter(n => act_proofs[n].status === '????')
  .concat(exhaustiveness_obligations)
  .sort((a, b) => Math.random() - 0.5)
}

fs.writeFileSync(path.join(KLAB_OUT, "obligations.batch"), obligations.join("\n"))

if(write_prelude) {
  console.log('write prelude')
  fs.writeFileSync(path.join(KLAB_OUT, "prelude.smt2"), prelude_str)
}

var {rules_str, write_rules} = makeRules(config, true);
if(write_rules) {
  console.log('write rules.k')
  fs.writeFileSync(path.join(KLAB_OUT, "rules.k"), rules_str)
}

// Implementations
const wrapModule = (name, str) => `requires "data.k"\n\nmodule ${name}\n    imports EVM-DATA\n\n${str}\n\nendmodule`
fs.writeFileSync(path.join(KLAB_OUT, "bin_runtime.k"), wrapModule("BIN_RUNTIME", bin_defs))
